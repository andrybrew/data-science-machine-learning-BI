{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/data-science-machine-learning-BI/blob/main/006a_emotion_analysis_multi_class_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDUZzG0xQKaI"
      },
      "source": [
        "# **Emotion Analysis with IndoBERT (Multi-Class Classification)**\n",
        "\n",
        "This notebook will demonstrate how to analyze emotions using **IndoBERT**, a pre-trained transformer model specialized for the Indonesian language. The dataset to be analyzed will consist of Twitter posts related to interest rate policies by **Bank Indonesia**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Interest Rate Dataset**\n",
        "The interest rate is a critical tool used by central banks like **Bank Indonesia** to influence the country's economic activities. It affects how much it costs to borrow money and the return on savings, thus directly impacting people's spending and saving behaviors.\n",
        "\n",
        "The recent decision by the **Board of Governors of Bank Indonesia** to increase the **BI-7 day reverse repo rate** by **25 basis points to 6%** is a strategic move to tackle economic challenges like **inflation** or **currency depreciation**. Such changes can have significant effects on various sectors, including loans, mortgages, savings, and investments. Understanding the public's reaction to the interest rate hike will yield insights into the general sentiment and expectations of this policy decision on everyday lives and economic outlooks.\n",
        "\n",
        "### **Data Source:** Twitter  \n",
        "- **Keyword:** suku bunga since:2023-10-19  \n",
        "- **Collection Date:** October 22, 2023  \n",
        "- **Total Tweets:** 503  \n",
        "- **Language:** Bahasa Indonesia  \n"
      ],
      "metadata": {
        "id": "V_CalVwhsn_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Required Libraries**\n",
        "We will install and import the necessary libraries for text processing, emotion classification, and visualization."
      ],
      "metadata": {
        "id": "vNsHF1m8SGWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xw1mxj2JQWzq"
      },
      "outputs": [],
      "source": [
        "# Install Huggingface Transformers\n",
        "! pip install huggingface transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "6wZWQoXCTgZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Importing Dataset**\n",
        "We will load the dataset using **pandas.read_csv()** from a publicly available URL."
      ],
      "metadata": {
        "id": "OWmOaOF4WDR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the dataset from GitHub\n",
        "data_url = \"https://raw.githubusercontent.com/andrybrew/IHT-SEM1302-30Okt/main/data/001_suku-bunga.csv\"\n",
        "\n",
        "# Using pandas read_csv function to load the data from the URL directly into a DataFrame\n",
        "df_tweet = pd.read_csv(data_url)"
      ],
      "metadata": {
        "id": "jZpa9wOZWMdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Loading the IndoBERT Model**\n",
        "We will use the **thoriqfy/indobert-emotion-classification** model from Hugging Face to classify emotions. The necessary tokenizer and model will be set up for processing."
      ],
      "metadata": {
        "id": "-qoAExhiSqfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Pretrained Model for Emotion Classification\n",
        "emotion_pretrained = \"thoriqfy/indobert-emotion-classification\"\n",
        "\n",
        "# Set Model and Tokenizer for Emotion Classification\n",
        "emotion_tokenizer = BertTokenizer.from_pretrained(emotion_pretrained)\n",
        "emotion_config = BertConfig.from_pretrained(emotion_pretrained)\n",
        "emotion_model = BertForSequenceClassification.from_pretrained(emotion_pretrained, config=emotion_config)\n",
        "\n",
        "# Create emotion classifier using huggingface pipeline\n",
        "emotion_analysis = pipeline(\"text-classification\", model=emotion_model, tokenizer=emotion_tokenizer)"
      ],
      "metadata": {
        "id": "N-iz-igUVWJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Pretrained Model\n",
        "pretrained = \"thoriqfy/indobert-emotion-classification\""
      ],
      "metadata": {
        "id": "Fv3lvARZagIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBQjyYIwQLTl"
      },
      "outputs": [],
      "source": [
        "# Set Model and Tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(pretrained)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained)\n",
        "\n",
        "# Create sentiment classifier using huggingface pipeline\n",
        "emotion_analysis = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Performing Emotion Analysis**\n",
        "We will apply **IndoBERT** to classify each tweet into multiple emotion categories. The classification will include:\n",
        "- Tokenizing and truncating text to match model input requirements.\n",
        "- Predicting emotion labels based on model outputs.\n",
        "- Mapping predictions to predefined emotion categories."
      ],
      "metadata": {
        "id": "MsHKzXMlWP2G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCq8skXQQxli"
      },
      "outputs": [],
      "source": [
        "def get_emotion(text):\n",
        "    # Tokenize text and truncate to ensure it doesn't exceed the maximum limit\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = tokens[:min(len(tokens), 512 - 2)]  # 2 tokens for [CLS] and [SEP]\n",
        "\n",
        "    # Convert tokens back to string\n",
        "    truncated_text = tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "    # Get emotion\n",
        "    output = emotion_analysis(truncated_text)[0]\n",
        "    label = output['label']\n",
        "    score = output['score']\n",
        "    return label, score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with one sentence\n",
        "text = \"Kebijakannya kacau balau\"\n",
        "emotion, score = get_emotion(text)\n",
        "print(f'The emotion is: {emotion} with a score of: {score}')"
      ],
      "metadata": {
        "id": "z7NGB8Q4bmeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Applying Emotion Analysis to Dataset**\n",
        "We will apply the emotion classification function to each row in the dataset and create new columns for:\n",
        "- **Emotion Label** (e.g., Sadness, Anger, Happy, etc.)\n",
        "- **Confidence Score** of the classification"
      ],
      "metadata": {
        "id": "xmNiV1_KWbAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get emotion label for each row in dataframe\n",
        "df_tweet[['emotion', 'score']] = df_tweet['text'].apply(lambda x: pd.Series(get_emotion(x)))"
      ],
      "metadata": {
        "id": "TBbZjOs9bk4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnhAo-kYXVD2"
      },
      "outputs": [],
      "source": [
        "# Show Tweet with emotion\n",
        "df_tweet[['text', 'emotion', 'score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXtoH2KTVM0H"
      },
      "outputs": [],
      "source": [
        "# Visualise the emotion distribution\n",
        "sns.countplot(x ='emotion', data = df_tweet)"
      ]
    }
  ]
}